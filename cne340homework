#daothid tern
#CNE 340 fall 2023
#fork and clone the code to pycharm
#this code is imports  jobs from remotive.com to my local wamp server and should update every 4 hour checking a new jobs

import mysql.connector
import time
import json
import requests
from datetime import date
import html2text


# Connect to database
# You may need to edit the connect function based on your local settings.#I made a password for my database because it is important to do so Also make sure MySQL server is running or it will not connect
def connect_to_sql():
    conn = mysql.connector.connect(user='root', password='',
                                   host='127.0.0.1', database='cne340')

    return conn


# Create the table structure
def create_tables(cursor):
    # Creates table Must set Title to CHARSET utf8 unicode Source: http://mysql.rjweb.org/doc.php/charcoll.
    # Python is in latin-1 and error (Incorrect string value: '\xE2\x80\xAFAbi...') will occur if Description is not in unicode format due to the json data
    cursor.execute('''CREATE TABLE IF NOT EXISTS jobs (id INT PRIMARY KEY auto_increment, Job_id varchar(50) , 
    company varchar (300), Created_at DATE, url varchar(30000), Title LONGBLOB, Description LONGBLOB ); ''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS jobs (id INT PRIMARY KEY auto_increment, Job_id varchar(100) , 
        company varchar (500), Created_at DATE, url TEXT, Title LONGBLOB, Description LONGBLOB); ''')

# Query the database.
# You should not need to edit anything in this function
def query_sql(cursor, query):
    cursor.execute(query)
    return cursor

# Add a new job by extract all the required colum
# Add a new job
# Add a new job
def add_new_job(cursor, jobdetails):
    # Extract all required columns
    description = html2text.html2text(jobdetails['description'])
    date = jobdetails['publication_date'][0:10]
    query = "INSERT INTO jobs (Job_id, company, Created_at, url, Title, Description) VALUES (%s, %s, %s, %s, %s, %s)"
    values = (jobdetails['id'], jobdetails['company_name'], date, jobdetails['url'], '', description)
    cursor.execute(query, values)
    cursor.connection.commit()
    return cursor.rowcount

# Check if new job
def check_if_job_exists(cursor, job_details):
    #Add your code here
    query = "SELECT id FROM jobs WHERE Job_id = %s"
    data = (job_details['id'],)
    cursor.execute(query, data)
    return cursor.fetchone() is not None
# Deletes job
def delete_job(cursor, jobdetails):
    #Add your code here
    query = "UPDATE"
    query = "DELETE FROM jobs WHERE Job_id = %s"
    data = (jobdetails['id'],)
    cursor.execute(query, data)
    return query_sql(cursor, query)


# Grab new jobs from a website, Parses JSON code and inserts the data into a list of dictionaries do not need to edit
def fetch_new_jobs():
    query = requests.get("https://remotive.com/api/remote-jobs")
    datas = json.loads(query.text)

    return datas


# Main area of the code. Should not need to edit
def jobhunt(cursor):
    # Fetch jobs from website
    jobpage = fetch_new_jobs()  # Gets API website and holds the json data in it as a list
    # use below print statement to view list in json format
    # print(jobpage)
    jobpage = fetch_new_jobs()
    print(" Getting you  new jobs!")
    add_or_delete_job(jobpage, cursor)

def add_or_delete_job(jobpage, cursor):
    for jobdetails in jobpage['jobs']:
        is_job_found = check_if_job_exists(cursor, jobdetails)

        if is_job_found:
            delete_job_from_db(cursor, jobdetails)
        else:
            add_new_job(cursor, jobdetails)
            print("New Job Found!!!")

# Setup portion of the program. Take arguments and set up the script
# You should not need to edit anything here.
def main():
    # Important, rest are supporting functions
    # Connect to SQL and get cursor

    conn = connect_to_sql()
    cursor = conn.cursor()
    create_tables(cursor)

    while (1):  # Infinite Loops. Only way to kill it is to crash or manually crash it. We did this as a background process/passive scraper
        jobhunt(cursor)
        time.sleep(21600)  # Sleep for 1h, this is ran every hour because API or web interfaces have request limits. Your reqest will get blocked.

# Sleep does a rough cycle count, system is not entirely accurate
# If you want to test if script works change time.sleep() to 10 seconds and delete your table in MySQL
if __name__ == '__main__':
    main()


